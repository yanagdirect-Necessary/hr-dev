import os
import json
import io
import requests
import streamlit as st
import pandas as pd
from datetime import datetime
from bs4 import BeautifulSoup
from openai import OpenAI
from dotenv import load_dotenv
import time
import hashlib
import difflib
from urllib.parse import urlparse

# =========================================================
# åŸºæœ¬è¨­å®š
# =========================================================
APP_TITLE = "äººäº‹è©•ä¾¡åˆ¶åº¦ è‡ªå‹•ç”ŸæˆAI"
APP_VERSION = "23.2.11"  # 23.2.10ä¿®æ­£ï¼ˆjsonå¿…é ˆ/é‡è¤‡å›é¿/é€²æ—å®‰å®šï¼‰ï¼‹ä»»æ„ã®ç’°å¢ƒå›ºå®šã‚¬ãƒ¼ãƒ‰

st.set_page_config(page_title=f"{APP_TITLE} v{APP_VERSION}", layout="centered")
load_dotenv()

# CSS: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ & å“è³ªç®¡ç†ãƒ‘ãƒãƒ«
st.markdown(
    """
    <style>
    .stProgress > div > div > div > div {
        background-image: linear-gradient(to right, #4cd964, #5ac8fa);
        background-color: #4cd964;
    }
    .control-panel {
        background-color: #262730;
        padding: 20px;
        border-radius: 10px;
        border: 1px solid #444;
        margin-bottom: 20px;
    }
    .panel-header {
        font-weight: bold;
        font-size: 1.2em;
        margin-bottom: 15px;
        color: #fff;
        border-bottom: 1px solid #555;
        padding-bottom: 5px;
    }
    .alert-box-warning {
        background-color: #332701;
        border-left: 5px solid #ffc107;
        padding: 10px;
        margin-bottom: 10px;
        color: #fff;
    }
    .alert-box-success {
        background-color: #0e2a10;
        border-left: 5px solid #28a745;
        padding: 10px;
        margin-bottom: 10px;
        color: #fff;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


def get_secret(key: str):
    return st.secrets[key] if key in st.secrets else os.getenv(key)


# =========================================================
# ç’°å¢ƒã‚¬ãƒ¼ãƒ‰ï¼ˆENVå›ºå®šï¼šAPP_ENVâ†’project_refã‚’ã‚³ãƒ¼ãƒ‰ã§æ‹˜æŸï¼‰
# =========================================================
APP_ENV = (get_secret("APP_ENV") or "").strip().lower()  # dev/demo/prod
ENV_LABEL = (get_secret("ENV_LABEL") or APP_ENV.upper()).strip()
STRICT_ENV_GUARD = str(get_secret("STRICT_ENV_GUARD") or "true").strip().lower() in ("1", "true", "yes", "on")

# â˜… æ›¸ãè¾¼ã¿å°ç·šã®å°å°ï¼ˆUIå´ã®ç‰©ç†ã‚¬ãƒ¼ãƒ‰ï¼‰
WRITE_ENABLED = str(get_secret("WRITE_ENABLED") or "false").strip().lower() in ("1", "true", "yes", "on")

# â˜…ã“ã“ã«ã€Œå„ç’°å¢ƒã® project_refã€ã‚’å›ºå®šã§æ›¸ãï¼ˆxxxx.supabase.co ã® xxxxï¼‰
# å„ªå…ˆé †ä½ï¼š
# 1) secrets ã® ENV_REF_DEV/DEMO/PROD ãŒå…¥ã£ã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ã†ï¼ˆé‹ç”¨ã§å·®ã—æ›¿ãˆå¯ï¼‰
# 2) ç„¡ã‘ã‚Œã°ã€ã“ã“ã«æ›¸ã„ãŸå›ºå®šå€¤ï¼ˆã‚ãªãŸãŒæç¤ºã—ãŸproject_refï¼‰ã‚’ä½¿ã†
ENV_TO_PROJECT_REF = {
    "dev":  (get_secret("ENV_REF_DEV")  or "xpaktdfzhinbwdchyltf").strip(),
    "demo": (get_secret("ENV_REF_DEMO") or "gwjaxkntwbcvnjubfjoz").strip(),
    "prod": (get_secret("ENV_REF_PROD") or "rrieppgrmutdhytoxekz").strip(),
}
# â€»å®Œå…¨ã«â€œã‚³ãƒ¼ãƒ‰å›ºå®šâ€ã«ã—ãŸã„ãªã‚‰ä¸Šã® get_secret(...) ã‚’æ¶ˆã—ã¦ç›´æ›¸ãã§ã‚‚OK
# ENV_TO_PROJECT_REF = {"dev":"xpaktdfzhinbwdchyltf","demo":"gwjaxkntwbcvnjubfjoz","prod":"rrieppgrmutdhytoxekz"}


def _extract_supabase_project_ref(url: str) -> str:
    try:
        host = urlparse(url).netloc
        if host.endswith(".supabase.co"):
            return host.split(".")[0]
        return ""
    except Exception:
        return ""


def _env_color(env: str) -> str:
    env = (env or "").lower()
    if env == "prod":
        return "#ff4d4d"
    if env == "dev":
        return "#4da3ff"
    return "#ffb84d"


def env_guard_or_stop():
    if APP_ENV not in ("dev", "demo", "prod"):
        st.error("APP_ENV ãŒæœªè¨­å®šã¾ãŸã¯ä¸æ­£ã§ã™ã€‚dev / demo / prod ã®ã„ãšã‚Œã‹ã«ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.markdown(
        f"""
        <div style="padding:8px 12px;border-radius:10px;background:{_env_color(APP_ENV)};color:white;
        font-weight:700;display:inline-block;margin-bottom:10px;">
        ENV: {ENV_LABEL}ï¼ˆ{APP_ENV}ï¼‰
        </div>
        """,
        unsafe_allow_html=True,
    )

    sb_url = (get_secret("SUPABASE_URL") or "").strip()
    if not sb_url:
        if STRICT_ENV_GUARD:
            st.error("SUPABASE_URL ãŒæœªè¨­å®šã§ã™ã€‚ç’°å¢ƒæ··ç·šã‚’é˜²ããŸã‚èµ·å‹•ã‚’åœæ­¢ã—ã¾ã™ã€‚")
            st.stop()
        return

    actual_ref = _extract_supabase_project_ref(sb_url)
    expected_ref = (ENV_TO_PROJECT_REF.get(APP_ENV) or "").strip()

    # â˜…å³æ ¼ãƒ¢ãƒ¼ãƒ‰ãªã‚‰ dev/demo/prod å…¨éƒ¨ã§ expected_ref æœªè¨­å®šã¯åœæ­¢ï¼ˆç©´ã‚’æ®‹ã•ãªã„ï¼‰
    if STRICT_ENV_GUARD and not expected_ref:
        st.error(f"{APP_ENV}ç’°å¢ƒã§ project_ref ãŒå›ºå®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ENV_TO_PROJECT_REF ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # expected_ref ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯å¿…ãšä¸€è‡´ãƒã‚§ãƒƒã‚¯
    if expected_ref:
        if not actual_ref:
            st.error("SUPABASE_URL ã‹ã‚‰ project_ref ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã€‚URLå½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        if actual_ref != expected_ref:
            st.error(
                "Supabaseæ¥ç¶šå…ˆãŒç’°å¢ƒã¨ä¸€è‡´ã—ã¾ã›ã‚“ï¼ˆèª¤æ¥ç¶šé˜²æ­¢ã®ãŸã‚åœæ­¢ï¼‰ã€‚\n\n"
                f"- ENV:      {APP_ENV}\n"
                f"- EXPECTED: {expected_ref}\n"
                f"- ACTUAL:   {actual_ref}\n\n"
                "Streamlit secrets ã® SUPABASE_URL ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚"
            )
            st.stop()


# =========================================================
# Secrets & OpenAI
# =========================================================
SUPABASE_URL = get_secret("SUPABASE_URL")
SUPABASE_KEY = get_secret("SUPABASE_SERVICE_ROLE_KEY")  # â€»å°†æ¥ç”¨ï¼ˆç¾çŠ¶æœªä½¿ç”¨ï¼‰
OPENAI_API_KEY = get_secret("OPENAI_API_KEY")
APP_PASSWORD = get_secret("APP_PASSWORD")
FIXED_COMPANY_NAME = get_secret("FIXED_COMPANY_NAME")
FIXED_COMPANY_URL = get_secret("FIXED_COMPANY_URL")

client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# =========================================================
# çµŒå–¶ç†è«–ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³
# =========================================================
THEORETICAL_BACKBONE = """
ã€AIãŒæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã§å¼·åˆ¶çš„ã«å‚ç…§ã™ã¹ã9äººã®å·¨åŒ ã¨ãã®ç†è«–ã€‘
1. Philosophy & Strategy: P.F.ãƒ‰ãƒ©ãƒƒã‚«ãƒ¼(è²¢çŒ®), M.ãƒãƒ¼ã‚¿ãƒ¼(ç«¶äº‰å„ªä½), J.ã‚³ãƒƒã‚¿ãƒ¼(å¤‰é©)
2. Structure & Balance: R.ã‚«ãƒ—ãƒ©ãƒ³(BSC), D.ã‚¦ãƒ«ãƒªãƒƒãƒ(æˆ¦ç•¥HR), M.ãƒ’ãƒ¼ã‚¹ãƒªãƒƒãƒ‰(HPWS)
3. Operation & Development: é‡ä¸­éƒæ¬¡éƒ(SECI), A.ãƒ‡ãƒ»ãƒ¯ãƒ¼ãƒ«(HPO), T.V.ãƒ©ã‚ª(äººæé–‹ç™º)
""".strip()

# =========================================================
# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š & å®šæ•°
# =========================================================
USER_PLAN = "standard"

FALLBACK_PHILOSOPHY = """
ã€é‡è¦ç†å¿µèªã€‘è‡ªç«‹æ”¯æ´ã€å€‹åˆ¥ã‚±ã‚¢ã€åœ°åŸŸåŒ…æ‹¬ã‚±ã‚¢ã€ãƒãƒ¼ãƒ å”åƒã€å°‚é–€æ€§å‘ä¸Šã€‚
ã€ç›®æŒ‡ã™çŠ¶æ…‹ã€‘åˆ©ç”¨è€…æ§˜ã®ç”Ÿæ´»ã®è³ªã®æœ€å¤§åŒ–ã¨ã€è·å“¡ã®ã‚„ã‚ŠãŒã„ã‚’ä¸¡ç«‹ã™ã‚‹ã€‚
""".strip()

DEFAULT_MAJOR_CATEGORIES = {
    "I": "ç¤¾ä¼šäººåŸºç¤ã¨è·æ¥­å€«ç†",
    "II": "ç†å¿µã¨çµŒå–¶æ–¹é‡ç†è§£",
    "III": "æ³•ä»¤éµå®ˆã¨åˆ¶åº¦ç†è§£",
    "IV": "å°‚é–€è·å‹™é‚è¡ŒåŠ›",
    "V": "è¨˜éŒ²ãƒ»å ±å‘Šãƒ»æƒ…å ±ç®¡ç†",
    "VI": "ãƒãƒ¼ãƒ é€£æºãƒ»å¤šè·ç¨®å”åƒ",
    "VII": "ãƒªã‚¹ã‚¯ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã¨å€«ç†åˆ¤æ–­",
    "VIII": "ICTãƒ»AIãƒ»DXæ¨é€²",
    "IX": "è‡ªå·±ç ”é‘½ã¨åœ°åŸŸè²¢çŒ®",
    "X": "ç¦åˆ©åšç”Ÿæ´»ç”¨ã¨å°†æ¥è¨­è¨ˆ",
}

ROMAN_ORDER = ["I", "II", "III", "IV", "V", "VI", "VII", "VIII", "IX", "X"]

USER_DEFINED_LEVELS = {
    "Lv1": {"çµŒé¨“å¹´æ•°": "å…¥ç¤¾ã€œ1å¹´æœªæº€", "æƒ³å®šå½¹è·": "æ–°ä»»è·å“¡ï¼åˆç´šè·å“¡", "selectable": True},
    "Lv2": {"çµŒé¨“å¹´æ•°": "1ã€œ3å¹´æœªæº€", "æƒ³å®šå½¹è·": "å®Ÿå‹™å®šç€æœŸè·å“¡ï¼ä¸€èˆ¬è·å“¡", "selectable": True},
    "Lv3": {"çµŒé¨“å¹´æ•°": "3å¹´ä»¥ä¸Š5å¹´æœªæº€", "æƒ³å®šå½¹è·": "ã‚µãƒ–ãƒªãƒ¼ãƒ€ãƒ¼ï¼ä¸­å …è·å“¡", "selectable": True},
    "Lv4": {"çµŒé¨“å¹´æ•°": "5å¹´ä»¥ä¸Š", "æƒ³å®šå½¹è·": "ä¸»ä»»ï¼ãƒãƒ¼ãƒ•", "selectable": False},
    "Lv5": {"çµŒé¨“å¹´æ•°": "7å¹´ä»¥ä¸Š", "æƒ³å®šå½¹è·": "å‰¯ç®¡ç†è€…ï¼ãƒªãƒ¼ãƒ€ãƒ¼å€™è£œ", "selectable": False},
    "Lv6": {"çµŒé¨“å¹´æ•°": "10å¹´ä»¥ä¸Š", "æƒ³å®šå½¹è·": "ç®¡ç†è€…ï¼ç®¡ç†è²¬ä»»è€…", "selectable": False},
    "Lv7": {"çµŒé¨“å¹´æ•°": "10å¹´ä»¥ä¸Š", "æƒ³å®šå½¹è·": "çµ±æ‹¬ç®¡ç†è€…ï¼æ‹ ç‚¹é•·", "selectable": False},
}

# =========================================================
# èªè¨¼
# =========================================================
def check_password():
    if not APP_PASSWORD:
        return True

    if "auth" not in st.session_state:
        st.session_state["auth"] = False
        st.session_state["USER_PLAN"] = "standard"

    if not st.session_state["auth"]:
        st.markdown("## ğŸ”’ ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™")
        plan_options = {
            "standard_demo": "Standard (ãƒ‡ãƒ¢ç”¨)",
            "advanced_demo": "Advanced (ãƒ‡ãƒ¢ç”¨)",
            "premium_demo": "Premium (ãƒ‡ãƒ¢ç”¨)",
        }
        selected_id = st.selectbox("ãƒ‡ãƒ¢ãƒ¦ãƒ¼ã‚¶ãƒ¼ID", list(plan_options.keys()), format_func=lambda x: plan_options[x])
        st.session_state["USER_PLAN_SELECTION"] = selected_id.split("_")[0]
        pwd = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
        if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
            if pwd == APP_PASSWORD:
                st.session_state["auth"] = True
                st.session_state["USER_PLAN"] = st.session_state["USER_PLAN_SELECTION"]
                st.rerun()
            else:
                st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")
        st.stop()

    global USER_PLAN
    USER_PLAN = st.session_state["USER_PLAN"]
    return True


# =========================================================
# URLåˆ†æ
# =========================================================
@st.cache_data(ttl=60 * 60, show_spinner=False)
def analyze_url_logic(url: str) -> str:
    try:
        headers = {"User-Agent": "HR-Eval-MVP/1.0"}
        resp = requests.get(url, headers=headers, timeout=12)
        if resp.status_code != 200:
            return ""
        resp.encoding = resp.apparent_encoding
        soup = BeautifulSoup(resp.text, "html.parser")
        for n in soup(["script", "style"]):
            n.decompose()
        candidates = []
        keywords = ["ç†å¿µ", "ãƒŸãƒƒã‚·ãƒ§ãƒ³", "ãƒ“ã‚¸ãƒ§ãƒ³", "Mission", "Vision", "Value", "æŒ‡é‡", "ç¤¾æ˜¯"]
        for tag in ["h1", "h2", "h3", "div", "p"]:
            for el in soup.find_all(tag):
                text = el.get_text(strip=True)
                if any(k in text for k in keywords) and 2 <= len(text) <= 80:
                    parent = el.find_parent()
                    if parent:
                        block = parent.get_text(strip=True, separator="\n")
                        if 30 <= len(block) <= 900:
                            candidates.append(block)
        uniq = list(dict.fromkeys(candidates))
        if uniq:
            return "\n\n".join(uniq[:3])
        if soup.title and soup.title.string:
            return f"ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘{soup.title.string}"
        return ""
    except Exception:
        return ""


# =========================================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤
# =========================================================
def get_major_categories():
    return DEFAULT_MAJOR_CATEGORIES


def default_weight_by_level(level: str) -> int:
    if level == "Lv1":
        return 1
    if level == "Lv2":
        return 2
    return 3


def normalize_weight(w, level: str) -> int:
    try:
        wi = int(w)
    except Exception:
        wi = default_weight_by_level(level)
    if wi < 1:
        wi = 1
    if wi > 5:
        wi = 5
    return wi


def to_display_df(items, major_names_map: dict):
    def sort_key(item):
        k = item.get("category_large_key")
        if k in ROMAN_ORDER:
            return ROMAN_ORDER.index(k)
        return 999

    sorted_items = sorted(items, key=sort_key)
    rows = []
    for it in sorted_items:
        key = (it.get("category_large_key") or "").strip()
        name = (it.get("category_large_name") or "").strip()
        if not name and key in major_names_map:
            name = major_names_map[key]
        major_disp = f"{key}. {name}" if key and name else (name or key or "")
        rows.append(
            {
                "å¤§åˆ†é¡": major_disp,
                "ä¸­åˆ†é¡": (it.get("category_medium") or "").strip(),
                "è¨­å•": (it.get("full_sentence") or "").strip(),
                "ã‚¦ã‚¨ã‚¤ãƒˆ": int(it.get("weight", 0)) if str(it.get("weight", "")).strip() != "" else 0,
            }
        )
    df = pd.DataFrame(rows)
    if df.empty:
        df = pd.DataFrame(columns=["å¤§åˆ†é¡", "ä¸­åˆ†é¡", "è¨­å•", "ã‚¦ã‚¨ã‚¤ãƒˆ"])
    df.insert(0, "NO", range(1, len(df) + 1))
    return df[["NO", "å¤§åˆ†é¡", "ä¸­åˆ†é¡", "è¨­å•", "ã‚¦ã‚¨ã‚¤ãƒˆ"]]


def to_excel(items, major_names_map: dict, meta: dict):
    df = to_display_df(items, major_names_map)
    meta_df = pd.DataFrame(
        [
            {"é …ç›®": "ä¼šç¤¾å", "å€¤": meta.get("company_name", "")},
            {"é …ç›®": "ä¼æ¥­URL", "å€¤": meta.get("company_url", "")},
            {"é …ç›®": "äº‹æ¥­æ‰€å", "å€¤": meta.get("office_name", "")},
            {"é …ç›®": "è·ç¨®", "å€¤": meta.get("role", "")},
            {"é …ç›®": "ãƒ¬ãƒ™ãƒ«", "å€¤": meta.get("level", "")},
            {"é …ç›®": "çµŒé¨“å¹´æ•°", "å€¤": meta.get("level_years", "")},
            {"é …ç›®": "æƒ³å®šå½¹è·", "å€¤": meta.get("level_role", "")},
            {"é …ç›®": "é©ç”¨å¹´åº¦", "å€¤": meta.get("generation_year", "")},
            {"é …ç›®": "è¨­å•æ•°", "å€¤": str(meta.get("count", ""))},
            {"é …ç›®": "ç”Ÿæˆæ—¥", "å€¤": meta.get("generated_at", "")},
            {"é …ç›®": "ãƒ—ãƒ©ãƒ³", "å€¤": meta.get("plan", "")},
            {"é …ç›®": "ç’°å¢ƒ", "å€¤": meta.get("env", "")},
        ]
    )
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        meta_df.to_excel(writer, index=False, sheet_name="ãƒ¡ã‚¿æƒ…å ±")
        df.to_excel(writer, index=False, sheet_name="è©•ä¾¡ã‚·ãƒ¼ãƒˆ")
    return output.getvalue()


def allocate_counts(total: int, keys: list, weights: dict) -> dict:
    n = len(keys)
    alloc = {k: 0 for k in keys}
    if total <= 0 or n == 0:
        return alloc

    if total < n:
        sorted_keys = sorted(keys, key=lambda k: float(weights.get(k, 1.0)), reverse=True)
        for k in sorted_keys[:total]:
            alloc[k] = 1
        return alloc

    wsum = sum(float(weights.get(k, 1.0)) for k in keys)
    if wsum <= 0:
        wsum = float(n)

    target = {k: round(total * float(weights.get(k, 1.0)) / wsum) for k in keys}
    for k in keys:
        if target[k] < 1:
            target[k] = 1

    diff = total - sum(target.values())
    sorted_keys = sorted(keys, key=lambda k: float(weights.get(k, 1.0)), reverse=True)
    i = 0
    while diff != 0 and i < 10000:
        k = sorted_keys[i % n]
        if diff > 0:
            target[k] += 1
            diff -= 1
        else:
            if target[k] > 1:
                target[k] -= 1
                diff += 1
        i += 1

    diff2 = total - sum(target.values())
    if diff2 != 0:
        target[sorted_keys[0]] += diff2

    return target


# =========================================================
# AIç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
# =========================================================
def _hash_text(s: str) -> str:
    return hashlib.sha256((s or "").encode("utf-8")).hexdigest()[:16]


@st.cache_data(ttl=60 * 60, show_spinner=False)
def cached_generate_mediums(cache_key: str, payload: dict) -> list:
    _ = cache_key
    return generate_mediums(**payload)


def generate_mediums(role, level, major_key, major_name, philosophy, values, ng, grow, philosophy_rate, company_name):
    if not client:
        return []

    sys = f"""
IMPORTANT: Output strictly in JSON format. (json)

ã‚ãªãŸã¯9äººã®çµŒå–¶ç†è«–(ãƒ‰ãƒ©ãƒƒã‚«ãƒ¼/é‡ä¸­/ã‚«ãƒ—ãƒ©ãƒ³ç­‰)ã‚’ä½“å¾—ã—ãŸäººäº‹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ã€ä¼šç¤¾ã€‘{company_name}
ã€è·ç¨®ã€‘{role}
ã€ãƒ¬ãƒ™ãƒ«ã€‘{level}
ã€å¤§åˆ†é¡ã€‘{major_key}. {major_name}
ã€ç†å¿µã€‘{philosophy}

ä¸­åˆ†é¡(è©•ä¾¡è¦³ç‚¹)ã‚’5ã€œ7å€‹ä½œæˆã›ã‚ˆã€‚
Output JSON: {{ "mediums": [ {{ "name": "...", "intent": "...", "weight": 1.0 }} ] }}
""".strip()

    try:
        res = client.chat.completions.create(
            model="gpt-4o",
            response_format={"type": "json_object"},
            messages=[{"role": "system", "content": sys}],
            temperature=0.4,
        )
        mediums = json.loads(res.choices[0].message.content).get("mediums", [])
        return mediums if isinstance(mediums, list) else []
    except Exception:
        return []


def call_model_for_questions(
    role,
    level,
    mk,
    mname,
    med,
    intent,
    count,
    phi,
    val,
    ng,
    gr,
    exist,
    rate,
    year,
    comp,
):
    if not client:
        return []

    existing_list = "\n".join([f"- {q}" for q in (exist or [])][-80:])

    sys = f"""
IMPORTANT: Output strictly in JSON format. (json)

ã‚ãªãŸã¯9äººã®çµŒå–¶ç†è«–ã‚’ä½“å¾—ã—ãŸäººäº‹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ã€Œ{mk}. {mname} > {med}ã€ã®è¨­å•ã‚’ä½œæˆã—ã¾ã™ã€‚

ã€ãƒ«ãƒ¼ãƒ«ã€‘
- æ–‡é ­ã«è·ç¨®åã¯å…¥ã‚Œãªã„
- ã€Œç›®çš„ï¼‹è¡Œå‹•ï¼‹æˆæœã€ã‚’1æ–‡ã«çµ±åˆã™ã‚‹
- æ–‡æœ«ã¯ã€Œã€œã—ã¦ã„ã‚‹ã€
- è¦ç´ åˆ†è§£(purpose, action, result)ã‚‚å‡ºåŠ›ã™ã‚‹
- æ—¢å­˜è¨­å•ã¨ã®é‡è¤‡ãƒ»é¡ä¼¼ã¯ç¦æ­¢ï¼ˆè¨€ã„æ›ãˆã‚‚ä¸å¯ï¼‰
- å‡ºåŠ›ä»¶æ•°ã¯å¿…ãš {count} ä»¶

ã€æ—¢å­˜è¨­å•ï¼ˆé‡è¤‡ç¦æ­¢ï¼‰ã€‘
{existing_list}

Output JSON:
{{
  "items": [
    {{
      "purpose": "...",
      "action": "...",
      "result": "...",
      "full_sentence": "...",
      "weight": 3
    }}
  ]
}}
""".strip()

    try:
        res = client.chat.completions.create(
            model="gpt-4o",
            response_format={"type": "json_object"},
            messages=[{"role": "system", "content": sys}],
            temperature=0.6,
        )
        items = json.loads(res.choices[0].message.content).get("items", [])
        return items if isinstance(items, list) else []
    except Exception:
        return []


def check_duplicates(items, threshold=0.75):
    duplicates = []
    n = len(items)
    for i in range(n):
        for j in range(i + 1, n):
            s1 = (items[i].get("full_sentence") or "").strip()
            s2 = (items[j].get("full_sentence") or "").strip()
            if not s1 or not s2:
                continue
            score = difflib.SequenceMatcher(None, s1, s2).ratio()
            if score >= threshold:
                k1 = items[i].get("category_large_key")
                k2 = items[j].get("category_large_key")
                dup_type = "group" if k1 == k2 else "global"
                duplicates.append((i, items[i], j, items[j], score, dup_type))
    return duplicates


def regenerate_specific_item(
    item,
    role,
    level,
    philosophy,
    values,
    ng,
    grow,
    philosophy_rate,
    generation_year,
    company_name,
    mode="duplicate",
    existing_questions=None,
):
    if not client:
        return item

    instruction = (
        "ä»–ã®è¨­å•ã¨é‡è¤‡ã—ãªã„ã‚ˆã†ã«ã€å…¨ãç•°ãªã‚‹åˆ‡ã‚Šå£ã§æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚"
        if mode == "duplicate"
        else "åŒã˜ä¸­åˆ†é¡å†…ã§ã€è©•ä¾¡ã®è¦–ç‚¹ã‚’å¤‰ãˆã¦ï¼ˆåˆ¥ã®è¦³å¯Ÿãƒã‚¤ãƒ³ãƒˆã§ï¼‰æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚"
    )

    existing_list = "\n".join([f"- {q}" for q in (existing_questions or [])][-80:])

    sys = f"""
IMPORTANT: Output strictly in JSON format. (json)

ã‚ãªãŸã¯äººäº‹è©•ä¾¡åˆ¶åº¦ã®å°‚é–€å®¶ã§ã™ã€‚
{instruction}

ã€å…ƒã®è¨­å•ã€‘
{item.get('full_sentence','')}

ã€å¤§åˆ†é¡ã€‘
{item.get('category_large_name','')}

ã€ä¸­åˆ†é¡ã€‘
{item.get('category_medium','')}

ã€æ—¢å­˜è¨­å•ï¼ˆé‡è¤‡ç¦æ­¢ï¼‰ã€‘
{existing_list}

Output JSON:
{{
  "purpose": "...",
  "action": "...",
  "result": "...",
  "full_sentence": "...",
  "weight": 3
}}
""".strip()

    try:
        res = client.chat.completions.create(
            model="gpt-4o",
            response_format={"type": "json_object"},
            messages=[{"role": "system", "content": sys}],
            temperature=0.7,
        )
        new_item = item.copy()
        new_item.update(json.loads(res.choices[0].message.content))
        return new_item
    except Exception:
        return item


def generate_items(role, level, total, phi, val, ng, gr, weights, names, rate, year, comp, thresh):
    major_keys = sorted([k for k in weights.keys() if k in ROMAN_ORDER], key=lambda x: ROMAN_ORDER.index(x))
    alloc = allocate_counts(total, major_keys, weights)

    final = []
    seen_q = set()
    total_steps = max(1, len(major_keys) * 6)
    step = 0
    all_mediums = {}

    bar = st.progress(0)
    status = st.empty()

    def _set_progress(step_now: int, cap: float) -> None:
        # 0ã€œ100 ã® int ã«çµ±ä¸€ï¼ˆç’°å¢ƒä¾å­˜ã®ä¸å…·åˆã‚’é¿ã‘ã‚‹ï¼‰
        p = min(step_now / total_steps, cap)
        bar.progress(int(p * 100))

    for mk in major_keys:
        need = int(alloc.get(mk, 0))
        if need <= 0:
            continue

        mname = names.get(mk, mk)
        step += 1
        _set_progress(step, 0.95)
        status.text(f"ä¸­åˆ†é¡ç”Ÿæˆ: {mk}. {mname}")

        payload = {
            "role": role,
            "level": level,
            "major_key": mk,
            "major_name": mname,
            "philosophy": phi,
            "values": val,
            "ng": ng,
            "grow": gr,
            "philosophy_rate": rate,
            "company_name": comp,
        }
        key = f"{comp}|{role}|{level}|{mk}|{mname}|{_hash_text(phi)}|{_hash_text(val)}|{_hash_text(ng)}|{_hash_text(gr)}|{rate}"
        meds = cached_generate_mediums(key, payload)
        if not meds:
            meds = [{"name": "åŸºæœ¬", "intent": "åŸºæœ¬", "weight": 1.0}]
        all_mediums[mk] = meds

        med_alloc = allocate_counts(
            need,
            [m.get("name", "") for m in meds if m.get("name")],
            {m.get("name", ""): float(m.get("weight", 1.0)) for m in meds if m.get("name")},
        )

        for m in meds:
            med_name = (m.get("name") or "").strip()
            med_intent = (m.get("intent") or "").strip()
            n_med = int(med_alloc.get(med_name, 0))
            if not med_name or n_med <= 0:
                continue

            rounds = 0
            while n_med > 0 and rounds < 3:
                rounds += 1
                step += 1
                _set_progress(step, 0.99)
                status.text(f"ç”Ÿæˆä¸­: {mk}. {mname} > {med_name}ï¼ˆæ®‹ã‚Š{n_med}ï¼‰")

                existing_questions = [x.get("full_sentence", "") for x in final if x.get("full_sentence")]
                got = call_model_for_questions(
                    role,
                    level,
                    mk,
                    mname,
                    med_name,
                    med_intent,
                    n_med,
                    phi,
                    val,
                    ng,
                    gr,
                    existing_questions,  # â˜…é‡è¤‡å›é¿ã®ãŸã‚æ¸¡ã™
                    rate,
                    year,
                    comp,
                )

                added = 0
                for it in got:
                    q = (it.get("full_sentence") or "").strip()
                    if not q or q in seen_q:
                        continue
                    seen_q.add(q)
                    final.append(
                        {
                            "category_large_key": mk,
                            "category_large_name": mname,
                            "category_medium": med_name,
                            "full_sentence": q,
                            "purpose": it.get("purpose", ""),
                            "action": it.get("action", ""),
                            "result": it.get("result", ""),
                            "weight": normalize_weight(it.get("weight"), level),
                        }
                    )
                    added += 1

                n_med -= added
                if added == 0:
                    break
                time.sleep(0.05)

            if len(final) >= total:
                break

        if len(final) >= total:
            break

    bar.progress(100)
    status.success("ç”Ÿæˆå®Œäº†")
    time.sleep(0.2)
    bar.empty()
    status.empty()

    st.session_state["mediums_debug"] = all_mediums
    st.session_state["duplicates_found"] = check_duplicates(final, threshold=thresh)
    return final[:total]


# =========================================================
# Main
# =========================================================
env_guard_or_stop()
check_password()

st.title(APP_TITLE)
st.caption(f"Version {APP_VERSION}ï½œPlan: {USER_PLAN}ï½œENV: {ENV_LABEL}ï¼ˆ{APP_ENV}ï¼‰")

defaults = {
    "company_name": "",
    "company_url": "",
    "company_philosophy_text": "",
    "office_philosophy_text": "",
    "office_name": "",
    "role": "ä»‹è­·è·",
    "values_text": "",
    "ng_text": "",
    "grow_text": "",
    "items": [],
    "philosophy_used": "",
    "mediums_debug": {},
    "duplicates_found": [],
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

majors = get_major_categories()
default_weights = {k: 1.0 for k in majors.keys()}
if "IV" in default_weights:
    default_weights["IV"] = 1.5

st.sidebar.markdown("## âš™ï¸ è¨­å®š")
if USER_PLAN == "premium":
    philosophy_rate = st.sidebar.slider("ç†å¿µå‡ºç¾ç‡", 0, 100, 30, 5)
    similarity_threshold = st.sidebar.slider("é¡ä¼¼è¨±å®¹åº¦", 0.5, 0.95, 0.75, 0.05)
elif USER_PLAN == "advanced":
    philosophy_rate = 30
    similarity_threshold = 0.75
    st.sidebar.caption("Advanced: ç†å¿µ30% / é¡ä¼¼åº¦0.75 å›ºå®š")
else:
    philosophy_rate = 5
    similarity_threshold = 0.8
    st.sidebar.caption("Standard: ç†å¿µ5% / é¡ä¼¼åº¦0.80 å›ºå®š")

selected_major_weights = default_weights.copy()
selected_major_names = majors.copy()

if USER_PLAN in ["advanced", "premium"]:
    st.sidebar.markdown("#### ğŸ’ å¤§åˆ†é¡è¨­å®š")
    if "custom_weights" not in st.session_state:
        st.session_state["custom_weights"] = default_weights.copy()
    current_weights = st.session_state["custom_weights"]

    edited_weights, edited_names = {}, {}
    for k in ROMAN_ORDER:
        if k not in majors:
            continue
        c1, c2 = st.sidebar.columns([0.2, 0.8])
        is_checked = c1.checkbox(k, value=True, key=f"check_{k}")
        user_name = c2.text_input(
            "Name",
            value=majors[k],
            key=f"name_{k}",
            disabled=not is_checked,
            label_visibility="collapsed",
        )
        if is_checked:
            edited_names[k] = user_name
            w = current_weights.get(k, default_weights.get(k, 1.0))
            edited_weights[k] = st.sidebar.slider(
                "é‡ã¿",
                0.5,
                3.0,
                float(w),
                0.1,
                key=f"weight_{k}",
                label_visibility="collapsed",
            )

    if not edited_weights:
        st.sidebar.warning("1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„")
        selected_major_weights, selected_major_names = default_weights, majors
    else:
        st.session_state["custom_weights"] = edited_weights
        selected_major_weights, selected_major_names = edited_weights, edited_names
else:
    selected_major_weights, selected_major_names = default_weights, majors

# Input Form
st.markdown("### 1. ä¼æ¥­æƒ…å ±")
company_locked = bool(FIXED_COMPANY_NAME or FIXED_COMPANY_URL)
company_name = st.text_input(
    "ä¼æ¥­å",
    value=FIXED_COMPANY_NAME or st.session_state["company_name"],
    disabled=company_locked,
)
company_url = st.text_input(
    "ä¼æ¥­URL",
    value=FIXED_COMPANY_URL or st.session_state["company_url"],
    disabled=company_locked,
)
if not company_locked:
    st.session_state["company_name"], st.session_state["company_url"] = company_name, company_url

effective_company_name = (FIXED_COMPANY_NAME or company_name).strip()
effective_company_url = (FIXED_COMPANY_URL or company_url).strip()

st.markdown("#### 1.1 ç†å¿µã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ")
st.session_state["company_philosophy_text"] = st.text_area(
    "ã€ä¼šç¤¾å…¨ä½“ã€‘ç†å¿µãƒ»ãƒŸãƒƒã‚·ãƒ§ãƒ³",
    st.session_state["company_philosophy_text"],
    height=100,
)
st.session_state["office_philosophy_text"] = st.text_area(
    "ã€äº‹æ¥­æ‰€å›ºæœ‰ã€‘ç¾å ´ã®è¡Œå‹•æŒ‡é‡",
    st.session_state["office_philosophy_text"],
    height=80,
)

st.markdown("### 1.5 äº‹æ¥­æ‰€æƒ…å ±")
st.session_state["office_name"] = st.text_input("äº‹æ¥­æ‰€å", value=st.session_state["office_name"])

st.markdown("### 2. è·ç¨®")
st.session_state["role"] = st.text_input("è·ç¨®", value=st.session_state["role"])

st.markdown("### 3. è©•ä¾¡ãƒ¬ãƒ™ãƒ«")
selectable_map = {f"{k}ï½œ{v['çµŒé¨“å¹´æ•°']}ï½œ{v['æƒ³å®šå½¹è·']}": k for k, v in USER_DEFINED_LEVELS.items() if v["selectable"]}
level_label = st.selectbox("ãƒ¬ãƒ™ãƒ«é¸æŠ", list(selectable_map.keys()), index=2)
level = selectable_map[level_label]

st.markdown("### 4. è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ")
if USER_PLAN in ["advanced", "premium"]:
    st.session_state["values_text"] = st.text_area("ä¾¡å€¤è¦³ãƒ»ç¤¾æ˜¯", st.session_state["values_text"], height=80)
    st.session_state["ng_text"] = st.text_area("ç¦æ­¢äº‹é …", st.session_state["ng_text"], height=80)
    st.session_state["grow_text"] = st.text_area("ä¼¸ã°ã—ãŸã„è¡Œå‹•", st.session_state["grow_text"], height=80)
else:
    st.caption("â€» ã‚¢ãƒ‰ãƒãƒ³ã‚¹ä»¥ä¸Šã§åˆ©ç”¨å¯èƒ½")

st.markdown("### 5. ç”Ÿæˆè¨­å®š")
c_y, c_c = st.columns([1, 2])
year = c_y.text_input("é©ç”¨å¹´åº¦", value=str(datetime.now().year + 1))
count = c_c.slider("è¨­å•æ•°", 10, 100, 40)

if st.button("è©•ä¾¡ã‚·ãƒ¼ãƒˆç”Ÿæˆï¼ˆAIï¼‰", type="primary"):
    if not client:
        st.error("APIã‚­ãƒ¼æœªè¨­å®š")
        st.stop()
    if not effective_company_name or not st.session_state["office_name"] or not st.session_state["role"]:
        st.error("å¿…é ˆé …ç›®ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        st.stop()

    with st.spinner("AIã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆãŒæ€è€ƒä¸­..."):
        phi_gen = (st.session_state["company_philosophy_text"] or "").strip()
        if not phi_gen:
            if effective_company_url:
                url_phi = analyze_url_logic(effective_company_url).strip()
                phi_gen = url_phi if url_phi else FALLBACK_PHILOSOPHY
            else:
                phi_gen = FALLBACK_PHILOSOPHY

        combined_phi = f"ã€ä¼šç¤¾å…¨ä½“ã€‘\n{phi_gen}\n\nã€äº‹æ¥­æ‰€å›ºæœ‰ã€‘\n{(st.session_state['office_philosophy_text'] or '').strip()}"

        items = generate_items(
            st.session_state["role"].strip(),
            level,
            count,
            combined_phi,
            st.session_state["values_text"].strip(),
            st.session_state["ng_text"].strip(),
            st.session_state["grow_text"].strip(),
            selected_major_weights,
            selected_major_names,
            philosophy_rate,
            year.strip(),
            effective_company_name,
            similarity_threshold,
        )
        st.session_state["items"] = items
        st.session_state["philosophy_used"] = combined_phi

# çµæœç”»é¢
if st.session_state["items"]:
    st.markdown("---")
    st.subheader("ğŸ“Š ç”Ÿæˆçµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ & å“è³ªç®¡ç†")

    # å“è³ªç®¡ç†ãƒ‘ãƒãƒ«
    st.markdown('<div class="control-panel">', unsafe_allow_html=True)
    st.markdown("<div class='panel-header'>ğŸ› ï¸ å“è³ªç®¡ç†ãƒ‘ãƒãƒ« (Quality Control)</div>", unsafe_allow_html=True)

    dups = st.session_state.get("duplicates_found", [])
    group_dups = [d for d in dups if d[5] == "group"]
    global_dups = [d for d in dups if d[5] == "global"]

    c1, c2 = st.columns(2)

    # 1. ã‚°ãƒ«ãƒ¼ãƒ—å†…é‡è¤‡
    with c1:
        st.markdown("**1. ã‚°ãƒ«ãƒ¼ãƒ—å†…é‡è¤‡** (åŒä¸€å¤§åˆ†é¡)")
        if group_dups:
            st.markdown(f"<div class='alert-box-warning'>âš ï¸ {len(group_dups)}ä»¶ã®é‡è¤‡ã‚’æ¤œçŸ¥</div>", unsafe_allow_html=True)
            for d in group_dups[:3]:
                st.caption(f"No.{d[0]+1} â‰’ No.{d[2]+1}ï¼ˆé¡ä¼¼åº¦: {d[4]:.2f}ï¼‰")

            if st.button("ğŸ”„ ã‚°ãƒ«ãƒ¼ãƒ—å†…é‡è¤‡ã‚’è§£æ¶ˆ", key="fix_grp", type="primary"):
                with st.spinner("ä¿®æ­£ä¸­..."):
                    items = st.session_state["items"]
                    for d in group_dups:
                        idx = d[2]
                        existing_questions = [x.get("full_sentence", "") for x in items if x.get("full_sentence")]
                        items[idx] = regenerate_specific_item(
                            items[idx],
                            st.session_state["role"],
                            level,
                            st.session_state["philosophy_used"],
                            st.session_state["values_text"],
                            st.session_state["ng_text"],
                            st.session_state["grow_text"],
                            philosophy_rate,
                            year,
                            effective_company_name,
                            mode="duplicate",
                            existing_questions=existing_questions,
                        )
                    st.session_state["items"] = items
                    st.session_state["duplicates_found"] = check_duplicates(items, similarity_threshold)
                    st.success("ä¿®æ­£å®Œäº†")
                    time.sleep(0.6)
                    st.rerun()
        else:
            st.markdown("<div class='alert-box-success'>âœ… é‡è¤‡ãªã—</div>", unsafe_allow_html=True)

    # 2. å…¨ä½“é‡è¤‡
    with c2:
        st.markdown("**2. å…¨ä½“é‡è¤‡** (å¤§åˆ†é¡ã¾ãŸã)")
        if global_dups:
            st.markdown(f"<div class='alert-box-warning'>âš ï¸ {len(global_dups)}ä»¶ã®é‡è¤‡ã‚’æ¤œçŸ¥</div>", unsafe_allow_html=True)
            for d in global_dups[:3]:
                st.caption(f"No.{d[0]+1} â‰’ No.{d[2]+1}ï¼ˆé¡ä¼¼åº¦: {d[4]:.2f}ï¼‰")

            if st.button("ğŸ”„ å…¨ä½“é‡è¤‡ã‚’è§£æ¶ˆ", key="fix_glb", type="primary"):
                with st.spinner("ä¿®æ­£ä¸­..."):
                    items = st.session_state["items"]
                    for d in global_dups:
                        idx = d[2]
                        existing_questions = [x.get("full_sentence", "") for x in items if x.get("full_sentence")]
                        items[idx] = regenerate_specific_item(
                            items[idx],
                            st.session_state["role"],
                            level,
                            st.session_state["philosophy_used"],
                            st.session_state["values_text"],
                            st.session_state["ng_text"],
                            st.session_state["grow_text"],
                            philosophy_rate,
                            year,
                            effective_company_name,
                            mode="duplicate",
                            existing_questions=existing_questions,
                        )
                    st.session_state["items"] = items
                    st.session_state["duplicates_found"] = check_duplicates(items, similarity_threshold)
                    st.success("ä¿®æ­£å®Œäº†")
                    time.sleep(0.6)
                    st.rerun()
        else:
            st.markdown("<div class='alert-box-success'>âœ… é‡è¤‡ãªã—</div>", unsafe_allow_html=True)

    st.markdown("---")

    # 3. è¦–ç‚¹å¤‰æ›´
    st.markdown("**3. è¦–ç‚¹å¤‰æ›´ (å€‹åˆ¥ãƒ–ãƒ©ãƒƒã‚·ãƒ¥ã‚¢ãƒƒãƒ—)**")
    c_sel, c_btn = st.columns([0.3, 0.7])
    target_no = c_sel.number_input("ä¿®æ­£å¯¾è±¡No", 1, len(st.session_state["items"]), 1)
    if c_btn.button(f"ğŸ”„ No.{target_no} ã‚’åˆ¥ã®è¦–ç‚¹ã§æ›¸ãç›´ã™", key="fix_ind"):
        with st.spinner("æ›¸ãç›´ã—ä¸­..."):
            idx = int(target_no) - 1
            items = st.session_state["items"]
            existing_questions = [x.get("full_sentence", "") for x in items if x.get("full_sentence")]
            items[idx] = regenerate_specific_item(
                items[idx],
                st.session_state["role"],
                level,
                st.session_state["philosophy_used"],
                st.session_state["values_text"],
                st.session_state["ng_text"],
                st.session_state["grow_text"],
                philosophy_rate,
                year,
                effective_company_name,
                mode="perspective",
                existing_questions=existing_questions,
            )
            st.session_state["items"] = items
            st.session_state["duplicates_found"] = check_duplicates(items, similarity_threshold)
            st.success("å®Œäº†")
            time.sleep(0.6)
            st.rerun()

    st.markdown("</div>", unsafe_allow_html=True)

    # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
    df = to_display_df(st.session_state["items"], selected_major_names)
    st.dataframe(df, hide_index=True, use_container_width=True)

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    meta = {
        "company_name": effective_company_name,
        "company_url": effective_company_url,
        "office_name": st.session_state["office_name"],
        "role": st.session_state["role"],
        "level": level,
        "level_years": USER_DEFINED_LEVELS[level]["çµŒé¨“å¹´æ•°"],
        "level_role": USER_DEFINED_LEVELS[level]["æƒ³å®šå½¹è·"],
        "generation_year": year,
        "count": count,
        "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "plan": USER_PLAN,
        "env": APP_ENV,
    }
    excel = to_excel(st.session_state["items"], selected_major_names, meta)

    c_dl, c_sv = st.columns([2, 1])
    c_dl.download_button(
        "â¬‡ Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        excel,
        f"è©•ä¾¡ã‚·ãƒ¼ãƒˆ_{st.session_state['office_name']}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        type="secondary",
    )

    # â€œç‰©ç†ã‚¬ãƒ¼ãƒ‰â€ã¨ã—ã¦ä¿å­˜å°ç·šã‚’å°å°ã§ãã‚‹ï¼ˆWRITE_ENABLED=false ãªã‚‰ãƒœã‚¿ãƒ³å‡ºã•ãªã„ï¼‰
    if WRITE_ENABLED:
        c_sv.button("ğŸ’¾ ã‚¯ãƒ©ã‚¦ãƒ‰ä¿å­˜ (æ¬¡å›)")
    else:
        c_sv.caption("ğŸ’¾ ã‚¯ãƒ©ã‚¦ãƒ‰ä¿å­˜ï¼šWRITE_ENABLED=falseï¼ˆå°å°ä¸­ï¼‰")

    if st.session_state["philosophy_used"]:
        with st.expander("ä½¿ç”¨ã—ãŸç†å¿µ"):
            st.text(st.session_state["philosophy_used"])

    if USER_PLAN in ["advanced", "premium"] and st.session_state["mediums_debug"]:
        with st.expander("æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ (ä¸­åˆ†é¡)"):
            for k, v in st.session_state["mediums_debug"].items():
                st.markdown(f"**{k}. {selected_major_names.get(k, k)}**")
                for m in v:
                    st.markdown(f"- {m.get('name','')}: {m.get('intent','')}")
